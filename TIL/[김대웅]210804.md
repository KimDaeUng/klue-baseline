# 21-08-04 TIL

- 작성자 : 김대웅
- 요약 : 2주차, Task 내용공유

# Intro
- KLUE 리더보드 사이트 정상화, 베이스라인 모델 공개

# NLI Task - 지현님
- 목적 : 두 문장 사이의 관계를 함의/모순/중립으로 분류
- 평가지표/최적화 : Accuracy/CE Loss
- 새롭게 알게된 점: 평가지표가 Accuracy만으로 충분하다는 근거가 의문이었는데,
이전 GLUE의 NLI 데이터셋이나 KorNLI 데이터셋 등 NLI와 관련된 데이터셋들이
모두 Accuracy를 사용했기 때문에 이렇게 선택한 듯하다.
--> 이전 것들이 그렇게 했다고 그 자체가 근거가 될 수는 없을 것 같다.
--> 데이터셋을 살펴봐도 3개 클래스가 거의 균등하게 분포되어 있음. 따라서 F1을 쓸 이유가 없음
- 전제 문장과 가설 문장의 조합 문제
  - 전제 문장을 기준으로 가설 문장이 바뀌면서 데이터셋 구성(?확인 필요)
  - 어떤 전제 문장의 경우 가설 문장이 세 가지 클래스 모두를 커버하지 않는 경우가 있음
- 데이터셋의 크기에 대한 의문
  - KorNLI나 기존 영문에 대한 NLI 데이터셋의 경우 SNLI(Stanford NLI) 570K,
    MNLI(455K)로 상당히 많은 편인데 3만여개만으로 모델 학습이나 평가에 과연 충분한 데이터셋일까?
      
# YNAT Task - 본인
- 데이터셋에 대한 탐색보다는 학습을 위한 템플릿 코드 제공
- **Fine-tuning a model on the YNAT Task**
  - HuggingFace Datasets을 활용하여 KLUE 데이터셋 쉽게 전처리하기
  - HuggingFace Hub에서 사전학습된 언어 모델을 다운로드 받아 사용하고, 학습한 모델을 업로드하여 공유하기
  - `Trainer` 객체를 사용하여 모델 학습 및 평가 & hyperparameter search하기
  - Weights & Biases를 활용하여 실험 관리하기  

- **앞으로 추가되어야할 내용**
  - Pretraining 직접 수행하기
    - 학습 코퍼스 수집 및 전처리
    - Pre-Tokenizer & Tokenizer
    - Pretraining

  - Data Augmentation
    - Easy Data Augmentation(EDA)
    - 순환번역
    - 요약모델

  - Data Imbalance Problem
    - `imbalanced-learn` 라이브러리를 활용한 over, under sampling
    - Loss function: class weights 설정

  - 더 큰 배치사이즈로 학습하기
    - FP16를 이용한 학습
    - Single GPU에서 DeepSpeed 사용

  - 더 빠르게 학습하기 
    - TPU를 이용한 학습
    - Multi-GPU에서 DeepSpeed 사용

# RE - 이승미님
- (추후 내용 보강)
